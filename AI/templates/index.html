<!-- templates/index.html -->
<!DOCTYPE html>
<html>
<head>
    <title>Gesture Recognition Visualizer</title>
    <style>
        .container { display: flex; gap: 20px; }
        #videoPreview { border: 2px solid #333; }
        #resultPanel { padding: 20px; background: #f0f0f0; }
        .landmark { position: absolute; width: 5px; height: 5px; background: red; }
    </style>
</head>
<body>
    <h1>Gesture Recognition Demo</h1>
    
    <div class="container">
        <div>
            <video id="videoPreview" width="640" height="480" autoplay></video>
            <div>
                <button onclick="startWebcam()">Start Webcam</button>
                <button onclick="stopWebcam()">Stop Webcam</button>
            </div>
        </div>
        
        <div id="resultPanel">
            <h2>Detection Results</h2>
            <p>Gesture: <span id="gestureResult">-</span></p>
            <p>Confidence: <span id="confidenceResult">-</span></p>
            <div id="landmarkOverlay" style="position: relative;"></div>
        </div>
    </div>

    <script>
        let ws = null;
        const video = document.getElementById('videoPreview');
        const canvas = document.createElement('canvas');
        const ctx = canvas.getContext('2d');

        async function startWebcam() {
            const stream = await navigator.mediaDevices.getUserMedia({ video: true });
            video.srcObject = stream;
            ws = new WebSocket(`ws://${window.location.host}/ws`);
            
            ws.onmessage = (event) => {
                const data = JSON.parse(event.data);
                updateResults(data);
                drawLandmarks(data.landmarks);
            };

            setInterval(() => {
                if (video.readyState === video.HAVE_ENOUGH_DATA) {
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    ctx.drawImage(video, 0, 0);
                    const frame = canvas.toDataURL('image/jpeg', 0.8);
                    ws.send(frame);
                }
            }, 100);  // 10 FPS
        }

        function stopWebcam() {
            if (video.srcObject) {
                video.srcObject.getTracks().forEach(track => track.stop());
            }
            if (ws) ws.close();
        }

        function updateResults(data) {
            if(data.error) {
                document.getElementById('gestureResult').textContent = 'No hand detected';
                document.getElementById('confidenceResult').textContent = '0%';
                return;
            }
            
            document.getElementById('gestureResult').textContent = data.gesture;
            document.getElementById('confidenceResult').textContent = 
                `${(data.confidence * 100).toFixed(1)}%`;
        }

        function drawLandmarks(landmarks) {
            const overlay = document.getElementById('landmarkOverlay');
            overlay.innerHTML = '';
            
            landmarks.forEach(([x, y], idx) => {
                const dot = document.createElement('div');
                dot.className = 'landmark';
                dot.style.left = `${x * 640}px`;
                dot.style.top = `${y * 480}px`;
                overlay.appendChild(dot);
            });
        }
    </script>
</body>
</html>